{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-Based Filtering model  \n",
    "Content-based filtering approaches leverage **description or attributes** from items the user has interacted to recommend similar items. It depends only on the user **previous choices**, making this method robust to **avoid the cold-start problem**. For textual items, like articles, news and books, it is simple to use the article **category** or **raw text** to build **item profiles** and **user profiles**.\n",
    "\n",
    "Suppose I watch a particular genre movie I will be recommended movies w.r.t that specific genre. The Title, Year of Release, Director, Cast are also helpful in identifying similar movie content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Using Rated Content to Recommend\n",
    "In this approach contents of the product are already **rated** and based on the **user’s preference**. An **item score** is predicted to products and recommendation can be made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually `rating table` (user rating), `item profile` (book genres) are the only material we've got.\n",
    "\n",
    "* `rating table`: user-to-book relationship\n",
    "* `item profile`: attribute-to-book relationship  \n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/08/81.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will create the `user profile` so that we can understand what attribute the users actually prefer.\n",
    "* `user profile`: user-to-attribute relationship  \n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/08/91.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, with the `user profile`, we can get all the item score which is the user preference from `user profile` and `item profile`.  \n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/08/121.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from merge_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import book csv with description, and more than 10 user ratings\n",
    "df_n_des = pd.read_csv('books_n_description.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>categories</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>Actresses</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>Medical</td>\n",
       "      <td>Describes the great flu epidemic of 1918, an o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>A Chinese immigrant who is convinced she is dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0440234743</td>\n",
       "      <td>The Testament</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Dell</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>A suicidal billionaire, a burnt-out Washington...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0452264464</td>\n",
       "      <td>Beloved (Plume Contemporary Fiction)</td>\n",
       "      <td>Toni Morrison</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>Plume</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Staring unflinchingly into the abyss of slaver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         isbn                                              title  \\\n",
       "0  0002005018                                       Clara Callan   \n",
       "1  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "2  0399135782                             The Kitchen God's Wife   \n",
       "3  0440234743                                      The Testament   \n",
       "4  0452264464               Beloved (Plume Contemporary Fiction)   \n",
       "\n",
       "                 author  pub_year              publisher categories  \\\n",
       "0  Richard Bruce Wright    2001.0  HarperFlamingo Canada  Actresses   \n",
       "1      Gina Bari Kolata    1999.0   Farrar Straus Giroux    Medical   \n",
       "2               Amy Tan    1991.0       Putnam Pub Group    Fiction   \n",
       "3          John Grisham    1999.0                   Dell    Fiction   \n",
       "4         Toni Morrison    1994.0                  Plume    Fiction   \n",
       "\n",
       "                                         description  \n",
       "0  In a small town in Canada, Clara Callan reluct...  \n",
       "1  Describes the great flu epidemic of 1918, an o...  \n",
       "2  A Chinese immigrant who is convinced she is dy...  \n",
       "3  A suicidal billionaire, a burnt-out Washington...  \n",
       "4  Staring unflinchingly into the abyss of slaver...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n_des.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15452, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n_des.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy to books_wd which categories cell is not null\n",
    "books_wd = df_n_des[df_n_des['categories'].notnull()].copy()\n",
    "\n",
    "# filter out books with less than 5 characters in categories\n",
    "books_wd = books_wd[books_wd['categories'].map(len) >1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1466, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_wd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have **1,466** books in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = books_wd[['isbn','categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Actresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0440234743</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0452264464</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         isbn categories\n",
       "0  0002005018  Actresses\n",
       "1  0374157065    Medical\n",
       "2  0399135782    Fiction\n",
       "3  0440234743    Fiction\n",
       "4  0452264464    Fiction"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding for category\n",
    "df_genre = pd.get_dummies(df_item['categories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let’s treat all articles as having unit weight.  \n",
    "For binary representation, we can perform normalization by dividing the term occurrence by the sqrt of number of attributes in the article.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized\n",
    "df_genre_normalized = df_genre.apply(lambda x: x/np.sqrt(df_genre.sum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create item profile\n",
    "df_item = pd.concat([df_item, df_genre_normalized], axis=1)\n",
    "\n",
    "df_item.drop(columns='categories', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item.sort_values('isbn', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item.set_index('isbn', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accidents</th>\n",
       "      <th>Action and adventure</th>\n",
       "      <th>Actors</th>\n",
       "      <th>Actresses</th>\n",
       "      <th>Adoptees</th>\n",
       "      <th>Adventure stories</th>\n",
       "      <th>Affirmations</th>\n",
       "      <th>African American fiction</th>\n",
       "      <th>African American men</th>\n",
       "      <th>African American psychologists</th>\n",
       "      <th>...</th>\n",
       "      <th>Ryan, Jack (Fictitious character)</th>\n",
       "      <th>Savich, Dillon (Fictitious character)</th>\n",
       "      <th>Science fiction</th>\n",
       "      <th>Self-Help</th>\n",
       "      <th>Social Science</th>\n",
       "      <th>Star Trek fiction</th>\n",
       "      <th>Travel</th>\n",
       "      <th>Travelers' writings</th>\n",
       "      <th>True Crime</th>\n",
       "      <th>Yorkshire (England)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0002005018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000648302X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000649840X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020264763</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020264801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accidents  Action and adventure  Actors  Actresses  Adoptees  \\\n",
       "isbn                                                                       \n",
       "0002005018        0.0                   0.0     0.0        1.0       0.0   \n",
       "000648302X        0.0                   0.0     0.0        0.0       0.0   \n",
       "000649840X        0.0                   0.0     0.0        0.0       0.0   \n",
       "0020264763        0.0                   0.0     0.0        0.0       0.0   \n",
       "0020264801        0.0                   0.0     0.0        0.0       0.0   \n",
       "\n",
       "            Adventure stories  Affirmations  African American fiction  \\\n",
       "isbn                                                                    \n",
       "0002005018                0.0           0.0                       0.0   \n",
       "000648302X                0.0           0.0                       0.0   \n",
       "000649840X                0.0           0.0                       0.0   \n",
       "0020264763                0.0           0.0                       0.0   \n",
       "0020264801                0.0           0.0                       0.0   \n",
       "\n",
       "            African American men  African American psychologists  \\\n",
       "isbn                                                               \n",
       "0002005018                   0.0                             0.0   \n",
       "000648302X                   0.0                             0.0   \n",
       "000649840X                   0.0                             0.0   \n",
       "0020264763                   0.0                             0.0   \n",
       "0020264801                   0.0                             0.0   \n",
       "\n",
       "                   ...           Ryan, Jack (Fictitious character)  \\\n",
       "isbn               ...                                               \n",
       "0002005018         ...                                         0.0   \n",
       "000648302X         ...                                         0.0   \n",
       "000649840X         ...                                         0.0   \n",
       "0020264763         ...                                         0.0   \n",
       "0020264801         ...                                         0.0   \n",
       "\n",
       "            Savich, Dillon (Fictitious character)  Science fiction  Self-Help  \\\n",
       "isbn                                                                            \n",
       "0002005018                                    0.0              0.0        0.0   \n",
       "000648302X                                    0.0              0.0        0.0   \n",
       "000649840X                                    0.0              0.0        0.0   \n",
       "0020264763                                    0.0              0.0        0.0   \n",
       "0020264801                                    0.0              0.0        0.0   \n",
       "\n",
       "            Social Science  Star Trek fiction  Travel  Travelers' writings  \\\n",
       "isbn                                                                         \n",
       "0002005018             0.0                0.0     0.0                  0.0   \n",
       "000648302X             0.0                0.0     0.0                  0.0   \n",
       "000649840X             0.0                0.0     0.0                  0.0   \n",
       "0020264763             0.0                0.0     0.0                  0.0   \n",
       "0020264801             0.0                0.0     0.0                  0.0   \n",
       "\n",
       "            True Crime  Yorkshire (England)  \n",
       "isbn                                         \n",
       "0002005018         0.0                  0.0  \n",
       "000648302X         0.0                  0.0  \n",
       "000649840X         0.0                  0.0  \n",
       "0020264763         0.0                  0.0  \n",
       "0020264801         0.0                  0.0  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1466, 158)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `df_item`, there are **1,466** books and **158** genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the merged dataframe of `books`, `ratings`, `users` and get the record which matched the 1,466 books in `df_item`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged = merge_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>url_s</th>\n",
       "      <th>url_m</th>\n",
       "      <th>url_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "      <td>tyler, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>usa</td>\n",
       "      <td>texas</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>cincinnati, ohio, usa</td>\n",
       "      <td>23.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>ohio</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6543</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "      <td>strafford, missouri, usa</td>\n",
       "      <td>34.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>missouri</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8680</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>st. charles county, missouri, usa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>missouri</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10314</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>9</td>\n",
       "      <td>beaverton, oregon, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>usa</td>\n",
       "      <td>oregon</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user        isbn  rating                           location   age  \\\n",
       "0  276725  034545104X       0                  tyler, texas, usa   NaN   \n",
       "1    2313  034545104X       5              cincinnati, ohio, usa  23.0   \n",
       "2    6543  034545104X       0           strafford, missouri, usa  34.0   \n",
       "3    8680  034545104X       5  st. charles county, missouri, usa   2.0   \n",
       "4   10314  034545104X       9             beaverton, oregon, usa   NaN   \n",
       "\n",
       "  country   province                 title      author  pub_year  \\\n",
       "0     usa      texas  Flesh Tones: A Novel  M. J. Rose    2002.0   \n",
       "1     usa       ohio  Flesh Tones: A Novel  M. J. Rose    2002.0   \n",
       "2     usa   missouri  Flesh Tones: A Novel  M. J. Rose    2002.0   \n",
       "3     usa   missouri  Flesh Tones: A Novel  M. J. Rose    2002.0   \n",
       "4     usa     oregon  Flesh Tones: A Novel  M. J. Rose    2002.0   \n",
       "\n",
       "          publisher                                              url_s  \\\n",
       "0  Ballantine Books  http://images.amazon.com/images/P/034545104X.0...   \n",
       "1  Ballantine Books  http://images.amazon.com/images/P/034545104X.0...   \n",
       "2  Ballantine Books  http://images.amazon.com/images/P/034545104X.0...   \n",
       "3  Ballantine Books  http://images.amazon.com/images/P/034545104X.0...   \n",
       "4  Ballantine Books  http://images.amazon.com/images/P/034545104X.0...   \n",
       "\n",
       "                                               url_m  \\\n",
       "0  http://images.amazon.com/images/P/034545104X.0...   \n",
       "1  http://images.amazon.com/images/P/034545104X.0...   \n",
       "2  http://images.amazon.com/images/P/034545104X.0...   \n",
       "3  http://images.amazon.com/images/P/034545104X.0...   \n",
       "4  http://images.amazon.com/images/P/034545104X.0...   \n",
       "\n",
       "                                               url_l  \n",
       "0  http://images.amazon.com/images/P/034545104X.0...  \n",
       "1  http://images.amazon.com/images/P/034545104X.0...  \n",
       "2  http://images.amazon.com/images/P/034545104X.0...  \n",
       "3  http://images.amazon.com/images/P/034545104X.0...  \n",
       "4  http://images.amazon.com/images/P/034545104X.0...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11676     11144\n",
       "198711     6456\n",
       "153662     5814\n",
       "98391      5779\n",
       "35859      5646\n",
       "212898     4289\n",
       "278418     3996\n",
       "76352      3329\n",
       "110973     2971\n",
       "235105     2943\n",
       "Name: user, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top users number and their number of ratings given\n",
    "df_merged.user.value_counts().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_merged[df_merged['isbn'].isin(df_item.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72821, 14)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>url_s</th>\n",
       "      <th>url_m</th>\n",
       "      <th>url_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>276746</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>0</td>\n",
       "      <td>fort worth, ,</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Manhattan Hunt Club</td>\n",
       "      <td>JOHN SAUL</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>278026</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>8</td>\n",
       "      <td>east orange, new jersey, usa</td>\n",
       "      <td>56.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>new jersey</td>\n",
       "      <td>Manhattan Hunt Club</td>\n",
       "      <td>JOHN SAUL</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>243</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>6</td>\n",
       "      <td>arden hills, minnesota, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>usa</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>Manhattan Hunt Club</td>\n",
       "      <td>JOHN SAUL</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>645</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>0</td>\n",
       "      <td>ottawa, ontario, canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>canada</td>\n",
       "      <td>ontario</td>\n",
       "      <td>Manhattan Hunt Club</td>\n",
       "      <td>JOHN SAUL</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2010</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>0</td>\n",
       "      <td>colfax, illinois, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>usa</td>\n",
       "      <td>illinois</td>\n",
       "      <td>Manhattan Hunt Club</td>\n",
       "      <td>JOHN SAUL</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0449006522.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user        isbn  rating                      location   age  country  \\\n",
       "501  276746  0449006522       0                 fort worth, ,   NaN            \n",
       "502  278026  0449006522       8  east orange, new jersey, usa  56.0      usa   \n",
       "503     243  0449006522       6   arden hills, minnesota, usa   NaN      usa   \n",
       "504     645  0449006522       0       ottawa, ontario, canada   NaN   canada   \n",
       "505    2010  0449006522       0         colfax, illinois, usa   NaN      usa   \n",
       "\n",
       "        province                title     author  pub_year         publisher  \\\n",
       "501               Manhattan Hunt Club  JOHN SAUL    2002.0  Ballantine Books   \n",
       "502   new jersey  Manhattan Hunt Club  JOHN SAUL    2002.0  Ballantine Books   \n",
       "503    minnesota  Manhattan Hunt Club  JOHN SAUL    2002.0  Ballantine Books   \n",
       "504      ontario  Manhattan Hunt Club  JOHN SAUL    2002.0  Ballantine Books   \n",
       "505     illinois  Manhattan Hunt Club  JOHN SAUL    2002.0  Ballantine Books   \n",
       "\n",
       "                                                 url_s  \\\n",
       "501  http://images.amazon.com/images/P/0449006522.0...   \n",
       "502  http://images.amazon.com/images/P/0449006522.0...   \n",
       "503  http://images.amazon.com/images/P/0449006522.0...   \n",
       "504  http://images.amazon.com/images/P/0449006522.0...   \n",
       "505  http://images.amazon.com/images/P/0449006522.0...   \n",
       "\n",
       "                                                 url_m  \\\n",
       "501  http://images.amazon.com/images/P/0449006522.0...   \n",
       "502  http://images.amazon.com/images/P/0449006522.0...   \n",
       "503  http://images.amazon.com/images/P/0449006522.0...   \n",
       "504  http://images.amazon.com/images/P/0449006522.0...   \n",
       "505  http://images.amazon.com/images/P/0449006522.0...   \n",
       "\n",
       "                                                 url_l  \n",
       "501  http://images.amazon.com/images/P/0449006522.0...  \n",
       "502  http://images.amazon.com/images/P/0449006522.0...  \n",
       "503  http://images.amazon.com/images/P/0449006522.0...  \n",
       "504  http://images.amazon.com/images/P/0449006522.0...  \n",
       "505  http://images.amazon.com/images/P/0449006522.0...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **72,821** ratings of the **1,466** books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.pivot_table(df_final, values='rating', index=['isbn'], columns = ['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user</th>\n",
       "      <th>10</th>\n",
       "      <th>100004</th>\n",
       "      <th>100009</th>\n",
       "      <th>10001</th>\n",
       "      <th>100029</th>\n",
       "      <th>100035</th>\n",
       "      <th>10005</th>\n",
       "      <th>100053</th>\n",
       "      <th>100066</th>\n",
       "      <th>100067</th>\n",
       "      <th>...</th>\n",
       "      <th>99885</th>\n",
       "      <th>99894</th>\n",
       "      <th>999</th>\n",
       "      <th>9991</th>\n",
       "      <th>99946</th>\n",
       "      <th>99955</th>\n",
       "      <th>99963</th>\n",
       "      <th>99973</th>\n",
       "      <th>99996</th>\n",
       "      <th>99997</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0002005018</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000648302X</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000649840X</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020264763</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020264801</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22950 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user        10  100004  100009  10001  100029  100035  10005  100053  100066  \\\n",
       "isbn                                                                           \n",
       "0002005018 NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN     NaN   \n",
       "000648302X NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN     NaN   \n",
       "000649840X NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN     NaN   \n",
       "0020264763 NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN     NaN   \n",
       "0020264801 NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN     NaN   \n",
       "\n",
       "user        100067  ...    99885  99894  999  9991  99946  99955  99963  \\\n",
       "isbn                ...                                                   \n",
       "0002005018     NaN  ...      NaN    NaN  NaN   NaN    NaN    NaN    NaN   \n",
       "000648302X     NaN  ...      NaN    NaN  NaN   NaN    NaN    NaN    NaN   \n",
       "000649840X     NaN  ...      NaN    NaN  NaN   NaN    NaN    NaN    NaN   \n",
       "0020264763     NaN  ...      NaN    NaN  NaN   NaN    NaN    NaN    NaN   \n",
       "0020264801     NaN  ...      NaN    NaN  NaN   NaN    NaN    NaN    NaN   \n",
       "\n",
       "user        99973  99996  99997  \n",
       "isbn                             \n",
       "0002005018    NaN    NaN    NaN  \n",
       "000648302X    NaN    NaN    NaN  \n",
       "000649840X    NaN    NaN    NaN  \n",
       "0020264763    NaN    NaN    NaN  \n",
       "0020264801    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 22950 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the user number\n",
    "users_no = rating.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty dataframe\n",
    "df_users = pd.DataFrame(columns = df_item.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accidents</th>\n",
       "      <th>Action and adventure</th>\n",
       "      <th>Actors</th>\n",
       "      <th>Actresses</th>\n",
       "      <th>Adoptees</th>\n",
       "      <th>Adventure stories</th>\n",
       "      <th>Affirmations</th>\n",
       "      <th>African American fiction</th>\n",
       "      <th>African American men</th>\n",
       "      <th>African American psychologists</th>\n",
       "      <th>...</th>\n",
       "      <th>Ryan, Jack (Fictitious character)</th>\n",
       "      <th>Savich, Dillon (Fictitious character)</th>\n",
       "      <th>Science fiction</th>\n",
       "      <th>Self-Help</th>\n",
       "      <th>Social Science</th>\n",
       "      <th>Star Trek fiction</th>\n",
       "      <th>Travel</th>\n",
       "      <th>Travelers' writings</th>\n",
       "      <th>True Crime</th>\n",
       "      <th>Yorkshire (England)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Accidents, Action and adventure, Actors, Actresses, Adoptees, Adventure stories, Affirmations, African American fiction, African American men, African American psychologists, Age groups, Ahab, Captain (Fictitious character), Alchemists, Alcoholism, Altruism, Alzheimer's disease, American fiction, American literature, Americans, Andalusia (Spain), Animals, Anti-Catholicism, Antiques, Apocalyptic literature, Arabic fiction, Art, Artists, Astrology, Authors, American, Authors, Chilean, Baggins, Frodo (Fictitious character), Banks, Alan (Fictitious character), Bible, Biographical fiction, Biography &amp; Autobiography, Body, Mind &amp; Spirit, Book clubs (Discussion groups), Books and reading, Boston (Mass.), Boulder (Colo.), Boxcar children (Fictitious characters), Boys, Brain, Brooklyn (New York, N.Y.), Brunetti, Guido (Fictitious character), Business &amp; Economics, Business intelligence, Businessmen, Businesswomen, Calhoun, Mackenzie (Fictitious character), California, Canon (Literarature), Catskill Mountains Region (N.Y.), Childlessness, Children's stories, Comics &amp; Graphic Novels, Computers, Conduct of life, Confession, Continental European fiction (Fictional works by one author)., Cooking, Courtship, Covenant, Thomas (Fictitious character), Crafts &amp; Hobbies, Creative activities and seat work, Curiosities and wonders, Design, Detective and mystery stories, Diary fiction, Donation of organs, tissues, etc, Dracula, Count (Fictitious character), Dragons, Drama, Drug abuse, Drug traffic, Duitse fiksie, Education, Egypt, End of the world, England, English fiction, FICTION, Fairies, Fairy tales, Families, Family &amp; Relationships, Famines, Fantasy, Fantasy fiction, Female offenders, Feminists, Fiction, Fiction in English, Florida, Foreign Language Study, Fortune-telling by colors, France, Frankenstein (Fictitious character), Geishas, Generation X, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 158 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22950/22950 [09:58<00:00, 38.38it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(users_no))):\n",
    "    working_df = df_item.mul(rating.iloc[:,i], axis=0)\n",
    "    working_df.replace(0, np.NaN, inplace=True)    \n",
    "    df_users.loc[users_no[i]] = working_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accidents</th>\n",
       "      <th>Action and adventure</th>\n",
       "      <th>Actors</th>\n",
       "      <th>Actresses</th>\n",
       "      <th>Adoptees</th>\n",
       "      <th>Adventure stories</th>\n",
       "      <th>Affirmations</th>\n",
       "      <th>African American fiction</th>\n",
       "      <th>African American men</th>\n",
       "      <th>African American psychologists</th>\n",
       "      <th>...</th>\n",
       "      <th>Ryan, Jack (Fictitious character)</th>\n",
       "      <th>Savich, Dillon (Fictitious character)</th>\n",
       "      <th>Science fiction</th>\n",
       "      <th>Self-Help</th>\n",
       "      <th>Social Science</th>\n",
       "      <th>Star Trek fiction</th>\n",
       "      <th>Travel</th>\n",
       "      <th>Travelers' writings</th>\n",
       "      <th>True Crime</th>\n",
       "      <th>Yorkshire (England)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100009</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100029</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accidents  Action and adventure  Actors  Actresses  Adoptees  \\\n",
       "10            NaN                   NaN     NaN        NaN       NaN   \n",
       "100004        NaN                   NaN     NaN        NaN       NaN   \n",
       "100009        NaN                   NaN     NaN        NaN       NaN   \n",
       "10001         NaN                   NaN     NaN        NaN       NaN   \n",
       "100029        NaN                   NaN     NaN        NaN       NaN   \n",
       "\n",
       "        Adventure stories  Affirmations  African American fiction  \\\n",
       "10                    NaN           NaN                       NaN   \n",
       "100004                NaN           NaN                       NaN   \n",
       "100009                NaN           NaN                       NaN   \n",
       "10001                 NaN           NaN                       NaN   \n",
       "100029                NaN           NaN                       NaN   \n",
       "\n",
       "        African American men  African American psychologists  \\\n",
       "10                       NaN                             NaN   \n",
       "100004                   NaN                             NaN   \n",
       "100009                   NaN                             NaN   \n",
       "10001                    NaN                             NaN   \n",
       "100029                   NaN                             NaN   \n",
       "\n",
       "               ...           Ryan, Jack (Fictitious character)  \\\n",
       "10             ...                                         NaN   \n",
       "100004         ...                                         NaN   \n",
       "100009         ...                                         NaN   \n",
       "10001          ...                                         NaN   \n",
       "100029         ...                                         NaN   \n",
       "\n",
       "        Savich, Dillon (Fictitious character)  Science fiction  Self-Help  \\\n",
       "10                                        NaN              NaN        NaN   \n",
       "100004                                    NaN              NaN        NaN   \n",
       "100009                                    NaN              NaN        NaN   \n",
       "10001                                     NaN              NaN        NaN   \n",
       "100029                                    NaN              NaN        NaN   \n",
       "\n",
       "        Social Science  Star Trek fiction  Travel  Travelers' writings  \\\n",
       "10                 NaN                NaN     NaN                  NaN   \n",
       "100004             NaN                NaN     NaN                  NaN   \n",
       "100009             NaN                NaN     NaN                  NaN   \n",
       "10001              NaN                NaN     NaN                  NaN   \n",
       "100029             NaN                NaN     NaN                  NaN   \n",
       "\n",
       "        True Crime  Yorkshire (England)  \n",
       "10             NaN                  NaN  \n",
       "100004         NaN                  NaN  \n",
       "100009         NaN                  NaN  \n",
       "10001          NaN                  NaN  \n",
       "100029         NaN                  NaN  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user profile\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF\n",
    "Let’s consider how common different terms are among our documents.  \n",
    "The dot product of article vectors and IDF vectors gives us the **weighted scores** of each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_frequency = df_item.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = 1/document_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an empty dataframe\n",
    "df_predict = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dot product of article vectors and IDF vectors gives us the weighted scores of each article.\n",
    "idf_df_item = df_item.mul(idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22950/22950 [04:38<00:00, 82.51it/s] \n"
     ]
    }
   ],
   "source": [
    "#user predict by tfidf\n",
    "for i in tqdm(range(len(users_no))):\n",
    "    working_df = idf_df_item.mul(df_users.iloc[i], axis=1)\n",
    "    df_predict[users_no[i]] = working_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100004</th>\n",
       "      <th>100009</th>\n",
       "      <th>10001</th>\n",
       "      <th>100029</th>\n",
       "      <th>100035</th>\n",
       "      <th>10005</th>\n",
       "      <th>100053</th>\n",
       "      <th>100066</th>\n",
       "      <th>100067</th>\n",
       "      <th>...</th>\n",
       "      <th>99885</th>\n",
       "      <th>99894</th>\n",
       "      <th>999</th>\n",
       "      <th>9991</th>\n",
       "      <th>99946</th>\n",
       "      <th>99955</th>\n",
       "      <th>99963</th>\n",
       "      <th>99973</th>\n",
       "      <th>99996</th>\n",
       "      <th>99997</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0002005018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000648302X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000649840X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020264763</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020264801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008687</td>\n",
       "      <td>0.006113</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>0.008366</td>\n",
       "      <td>0.008044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22950 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             10  100004    100009     10001  100029    100035  10005  \\\n",
       "isbn                                                                   \n",
       "0002005018  0.0     0.0  0.000000  0.000000     0.0  0.000000    0.0   \n",
       "000648302X  0.0     0.0  0.000000  0.000000     0.0  0.000000    0.0   \n",
       "000649840X  0.0     0.0  0.000000  0.000000     0.0  0.000000    0.0   \n",
       "0020264763  0.0     0.0  0.000000  0.000000     0.0  0.000000    0.0   \n",
       "0020264801  0.0     0.0  0.007722  0.009653     0.0  0.007722    0.0   \n",
       "\n",
       "              100053    100066    100067    ...     99885  99894       999  \\\n",
       "isbn                                        ...                              \n",
       "0002005018  0.000000  0.000000  0.000000    ...       0.0    0.0  0.000000   \n",
       "000648302X  0.000000  0.000000  0.000000    ...       0.0    0.0  0.000000   \n",
       "000649840X  0.000000  0.000000  0.000000    ...       0.0    0.0  0.000000   \n",
       "0020264763  0.000000  0.000000  0.000000    ...       0.0    0.0  0.000000   \n",
       "0020264801  0.008687  0.006113  0.006757    ...       0.0    0.0  0.006757   \n",
       "\n",
       "            9991     99946  99955  99963     99973     99996     99997  \n",
       "isbn                                                                    \n",
       "0002005018   0.0  0.000000    0.0    0.0  0.000000  0.000000  0.000000  \n",
       "000648302X   0.0  0.000000    0.0    0.0  0.000000  0.000000  0.000000  \n",
       "000649840X   0.0  0.000000    0.0    0.0  0.000000  0.000000  0.000000  \n",
       "0020264763   0.0  0.000000    0.0    0.0  0.000000  0.000000  0.000000  \n",
       "0020264801   0.0  0.005309    0.0    0.0  0.005792  0.008366  0.008044  \n",
       "\n",
       "[5 rows x 22950 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all user score predict of all books\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_1(user_no):\n",
    "    \n",
    "    #get all book isbn\n",
    "    isbn_no = df_predict.index\n",
    "    \n",
    "    #user predicted rating to all books\n",
    "    user_predicted_rating = df_predict[user_no]\n",
    "    \n",
    "    #combine book rating and book detail\n",
    "    user_rating_book_detail = pd.concat([user_predicted_rating,books_wd.set_index('isbn')], axis=1)\n",
    "    \n",
    "    #sort top 10 rating books\n",
    "    return user_rating_book_detail.sort_values(by=[user_no], ascending=False).iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kevin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>11676</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>categories</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>038542471X</th>\n",
       "      <td>10.0</td>\n",
       "      <td>The Client</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>Doubleday Books</td>\n",
       "      <td>California</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0525460543</th>\n",
       "      <td>10.0</td>\n",
       "      <td>The Prince of Egypt Collector's Edition Storybook</td>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dreamworks Entertainment</td>\n",
       "      <td>Bible</td>\n",
       "      <td>Recounts the Biblical story of Moses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558531025</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Life's Little Instruction Book (Life's Little ...</td>\n",
       "      <td>H. Jackson Brown</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Thomas Nelson</td>\n",
       "      <td>Conduct of life</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2277241202</th>\n",
       "      <td>10.0</td>\n",
       "      <td>L' Alchimiste</td>\n",
       "      <td>Paul Coelho</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Editions 84</td>\n",
       "      <td>Andalusia (Spain)</td>\n",
       "      <td>Conte philosophique - voyage - Espagne - Afriq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0060972777</th>\n",
       "      <td>9.0</td>\n",
       "      <td>This Boy's Life: A Memoir</td>\n",
       "      <td>Tobias Wolff</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>Perennial</td>\n",
       "      <td>Authors, American</td>\n",
       "      <td>The author chronicles the tumultuous events of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0553204963</th>\n",
       "      <td>9.0</td>\n",
       "      <td>James Herriots Yorkshire</td>\n",
       "      <td>James Herriot</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>Bantam Doubleday Dell</td>\n",
       "      <td>Yorkshire (England)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0399148612</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Without Fail (Jack Reacher Novels (Hardcover))</td>\n",
       "      <td>Lee Child</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>G. P. Putnam's Sons</td>\n",
       "      <td>Military police</td>\n",
       "      <td>Hired by the Secret Service to test their shie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0590442376</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Prom Dress</td>\n",
       "      <td>Lael Littke</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>Scholastic Paperbacks (Mm)</td>\n",
       "      <td>Antiques</td>\n",
       "      <td>The beautiful prom dress that Robin finds in h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>067101398X</th>\n",
       "      <td>8.0</td>\n",
       "      <td>End Game (Star Trek New Frontier, No 4)</td>\n",
       "      <td>Peter David</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Star Trek</td>\n",
       "      <td>Star Trek fiction</td>\n",
       "      <td>Captain Mackenzie Calhoun - Wearing a veneer o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0679442790</th>\n",
       "      <td>8.0</td>\n",
       "      <td>The Reader</td>\n",
       "      <td>Bernhard Schlink</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Female offenders</td>\n",
       "      <td>Hailed for its eroticism and the the moral cla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            11676                                              title  \\\n",
       "038542471X   10.0                                         The Client   \n",
       "0525460543   10.0  The Prince of Egypt Collector's Edition Storybook   \n",
       "1558531025   10.0  Life's Little Instruction Book (Life's Little ...   \n",
       "2277241202   10.0                                      L' Alchimiste   \n",
       "0060972777    9.0                          This Boy's Life: A Memoir   \n",
       "0553204963    9.0                           James Herriots Yorkshire   \n",
       "0399148612    9.0     Without Fail (Jack Reacher Novels (Hardcover))   \n",
       "0590442376    8.0                                         Prom Dress   \n",
       "067101398X    8.0            End Game (Star Trek New Frontier, No 4)   \n",
       "0679442790    8.0                                         The Reader   \n",
       "\n",
       "                      author  pub_year                   publisher  \\\n",
       "038542471X      John Grisham    1993.0             Doubleday Books   \n",
       "0525460543       Walt Disney       NaN    Dreamworks Entertainment   \n",
       "1558531025  H. Jackson Brown    1991.0               Thomas Nelson   \n",
       "2277241202       Paul Coelho       NaN                 Editions 84   \n",
       "0060972777      Tobias Wolff    1989.0                   Perennial   \n",
       "0553204963     James Herriot    1982.0       Bantam Doubleday Dell   \n",
       "0399148612         Lee Child    2002.0         G. P. Putnam's Sons   \n",
       "0590442376       Lael Littke    1989.0  Scholastic Paperbacks (Mm)   \n",
       "067101398X       Peter David    1997.0                   Star Trek   \n",
       "0679442790  Bernhard Schlink    1997.0                Random House   \n",
       "\n",
       "                     categories  \\\n",
       "038542471X           California   \n",
       "0525460543                Bible   \n",
       "1558531025      Conduct of life   \n",
       "2277241202    Andalusia (Spain)   \n",
       "0060972777    Authors, American   \n",
       "0553204963  Yorkshire (England)   \n",
       "0399148612      Military police   \n",
       "0590442376             Antiques   \n",
       "067101398X    Star Trek fiction   \n",
       "0679442790     Female offenders   \n",
       "\n",
       "                                                  description  \n",
       "038542471X                                                NaN  \n",
       "0525460543              Recounts the Biblical story of Moses.  \n",
       "1558531025                                                NaN  \n",
       "2277241202  Conte philosophique - voyage - Espagne - Afriq...  \n",
       "0060972777  The author chronicles the tumultuous events of...  \n",
       "0553204963                                                NaN  \n",
       "0399148612  Hired by the Secret Service to test their shie...  \n",
       "0590442376  The beautiful prom dress that Robin finds in h...  \n",
       "067101398X  Captain Mackenzie Calhoun - Wearing a veneer o...  \n",
       "0679442790  Hailed for its eroticism and the the moral cla...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input the user number (e.g. 11676) to get top 10 books recommendation\n",
    "recommender_1('11676')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros\n",
    "* **User independence**: collaborative filtering needs other users' rating to find the similarity between the users and then give the suggestion. Instead, content-based method only have to analyze the items and user profile for recommendation.\n",
    "* **Transparency**: collaborative method gives you the recommendation because some unknown users have the same taste like you, but content-based method can tell you they recommend you the items based on what features. \n",
    "* **No cold start**: opposite to collaborative filtering, new items can be suggested before being rated by a substantial number of users.\n",
    "\n",
    "### Cons\n",
    "* **Limited content analysis**: if the content does not contain enough information to discriminate the items precisely, the recommendation will be not precisely at the end.\n",
    "* **Over-specialization**: content-based method provides a limit degree of novelty, since it has to match up the features of profile and items. A totally perfect content-based filtering may suggest nothing \"surprised.\" \n",
    "* **New user**: when there's not enough information to build a solid profile for a user, the recommendation could not be provided correctly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference  \n",
    "https://www.analyticsvidhya.com/blog/2015/08/beginners-guide-learn-content-based-recommender-systems/  \n",
    "https://towardsdatascience.com/learning-to-make-recommendations-745d13883951  \n",
    "http://findoutyourfavorite.blogspot.com/2012/04/content-based-filtering.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
