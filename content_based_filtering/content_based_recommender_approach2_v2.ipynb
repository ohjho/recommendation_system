{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-Based Filtering model  \n",
    "Content-based filtering approaches leverage **description or attributes** from items the user has interacted to recommend similar items. It depends only on the user **previous choices**, making this method robust to **avoid the cold-start problem**. For textual items, like articles, news and books, it is simple to use the article **category** or **raw text** to build **item profiles** and **user profiles**.\n",
    "\n",
    "Suppose I watch a particular genre movie I will be recommended movies w.r.t that specific genre. The Title, Year of Release, Director, Cast are also helpful in identifying similar movie content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: Using Rated Content to Recommend\n",
    "In this approach contents of the product are already **rated** and based on the **user’s preference**. An **item score** is predicted to products and recommendation can be made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually `rating table` (user rating), `item profile` (book genres) are the only material we've got.\n",
    "\n",
    "* `rating table`: user-to-book relationship\n",
    "* `item profile`: attribute-to-book relationship  \n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/08/81.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will create the `user profile` so that we can understand what attribute the users actually prefer.\n",
    "* `user profile`: user-to-attribute relationship  \n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/08/91.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, with the `user profile`, we can get all the item score which is the user preference from `user profile` and `item profile`.  \n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/08/121.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6452: expected 8 fields, saw 9\\nSkipping line 43667: expected 8 fields, saw 10\\nSkipping line 51751: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 92038: expected 8 fields, saw 9\\nSkipping line 104319: expected 8 fields, saw 9\\nSkipping line 121768: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 144058: expected 8 fields, saw 9\\nSkipping line 150789: expected 8 fields, saw 9\\nSkipping line 157128: expected 8 fields, saw 9\\nSkipping line 180189: expected 8 fields, saw 9\\nSkipping line 185738: expected 8 fields, saw 9\\n'\n",
      "b'Skipping line 209388: expected 8 fields, saw 9\\nSkipping line 220626: expected 8 fields, saw 9\\nSkipping line 227933: expected 8 fields, saw 11\\nSkipping line 228957: expected 8 fields, saw 10\\nSkipping line 245933: expected 8 fields, saw 9\\nSkipping line 251296: expected 8 fields, saw 9\\nSkipping line 259941: expected 8 fields, saw 9\\nSkipping line 261529: expected 8 fields, saw 9\\n'\n",
      "/Users/Kevin/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2961: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/Kevin/Documents/Data Science/Xccelerate - Full-Time Data Science & Machine Learning/Collaborative Projects/Recommendation System/Data_cleaning.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df_users.age[(df_users.age == 0) | (df_users.age > 122)] = None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from merge_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import book csv with description, and more than 10 user ratings\n",
    "df_n_des = pd.read_csv('books_n_description.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>categories</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>Actresses</td>\n",
       "      <td>In a small town in Canada, Clara Callan reluct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>Medical</td>\n",
       "      <td>Describes the great flu epidemic of 1918, an o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>The Kitchen God's Wife</td>\n",
       "      <td>Amy Tan</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>Putnam Pub Group</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>A Chinese immigrant who is convinced she is dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0440234743</td>\n",
       "      <td>The Testament</td>\n",
       "      <td>John Grisham</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Dell</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>A suicidal billionaire, a burnt-out Washington...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0452264464</td>\n",
       "      <td>Beloved (Plume Contemporary Fiction)</td>\n",
       "      <td>Toni Morrison</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>Plume</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Staring unflinchingly into the abyss of slaver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         isbn                                              title  \\\n",
       "0  0002005018                                       Clara Callan   \n",
       "1  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "2  0399135782                             The Kitchen God's Wife   \n",
       "3  0440234743                                      The Testament   \n",
       "4  0452264464               Beloved (Plume Contemporary Fiction)   \n",
       "\n",
       "                 author  pub_year              publisher categories  \\\n",
       "0  Richard Bruce Wright    2001.0  HarperFlamingo Canada  Actresses   \n",
       "1      Gina Bari Kolata    1999.0   Farrar Straus Giroux    Medical   \n",
       "2               Amy Tan    1991.0       Putnam Pub Group    Fiction   \n",
       "3          John Grisham    1999.0                   Dell    Fiction   \n",
       "4         Toni Morrison    1994.0                  Plume    Fiction   \n",
       "\n",
       "                                         description  \n",
       "0  In a small town in Canada, Clara Callan reluct...  \n",
       "1  Describes the great flu epidemic of 1918, an o...  \n",
       "2  A Chinese immigrant who is convinced she is dy...  \n",
       "3  A suicidal billionaire, a burnt-out Washington...  \n",
       "4  Staring unflinchingly into the abyss of slaver...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n_des.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15452, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_n_des.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a copy to books_wd which categories cell is not null\n",
    "books_wd = df_n_des[df_n_des['categories'].notnull()].copy()\n",
    "\n",
    "# filter out books with less than 5 characters in categories\n",
    "books_wd = books_wd[books_wd['categories'].map(len) >1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1466, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_wd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have **1,466** books in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = books_wd[['isbn','categories']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Actresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0399135782</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0440234743</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0452264464</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         isbn categories\n",
       "0  0002005018  Actresses\n",
       "1  0374157065    Medical\n",
       "2  0399135782    Fiction\n",
       "3  0440234743    Fiction\n",
       "4  0452264464    Fiction"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encoding for category\n",
    "df_genre = pd.get_dummies(df_item['categories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let’s treat all articles as having unit weight.  \n",
    "For binary representation, we can perform normalization by dividing the term occurrence by the sqrt of number of attributes in the article.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalized\n",
    "df_genre_normalized = df_genre.apply(lambda x: x/np.sqrt(df_genre.sum(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create item profile\n",
    "df_item = pd.concat([df_item, df_genre_normalized], axis=1)\n",
    "\n",
    "df_item.drop(columns='categories', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item.sort_values('isbn', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item.set_index('isbn', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accidents</th>\n",
       "      <th>Action and adventure</th>\n",
       "      <th>Actors</th>\n",
       "      <th>Actresses</th>\n",
       "      <th>Adoptees</th>\n",
       "      <th>Adventure stories</th>\n",
       "      <th>Affirmations</th>\n",
       "      <th>African American fiction</th>\n",
       "      <th>African American men</th>\n",
       "      <th>African American psychologists</th>\n",
       "      <th>...</th>\n",
       "      <th>Ryan, Jack (Fictitious character)</th>\n",
       "      <th>Savich, Dillon (Fictitious character)</th>\n",
       "      <th>Science fiction</th>\n",
       "      <th>Self-Help</th>\n",
       "      <th>Social Science</th>\n",
       "      <th>Star Trek fiction</th>\n",
       "      <th>Travel</th>\n",
       "      <th>Travelers' writings</th>\n",
       "      <th>True Crime</th>\n",
       "      <th>Yorkshire (England)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0002005018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000648302X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000649840X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020264763</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020264801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accidents  Action and adventure  Actors  Actresses  Adoptees  \\\n",
       "isbn                                                                       \n",
       "0002005018        0.0                   0.0     0.0        1.0       0.0   \n",
       "000648302X        0.0                   0.0     0.0        0.0       0.0   \n",
       "000649840X        0.0                   0.0     0.0        0.0       0.0   \n",
       "0020264763        0.0                   0.0     0.0        0.0       0.0   \n",
       "0020264801        0.0                   0.0     0.0        0.0       0.0   \n",
       "\n",
       "            Adventure stories  Affirmations  African American fiction  \\\n",
       "isbn                                                                    \n",
       "0002005018                0.0           0.0                       0.0   \n",
       "000648302X                0.0           0.0                       0.0   \n",
       "000649840X                0.0           0.0                       0.0   \n",
       "0020264763                0.0           0.0                       0.0   \n",
       "0020264801                0.0           0.0                       0.0   \n",
       "\n",
       "            African American men  African American psychologists  \\\n",
       "isbn                                                               \n",
       "0002005018                   0.0                             0.0   \n",
       "000648302X                   0.0                             0.0   \n",
       "000649840X                   0.0                             0.0   \n",
       "0020264763                   0.0                             0.0   \n",
       "0020264801                   0.0                             0.0   \n",
       "\n",
       "                   ...           Ryan, Jack (Fictitious character)  \\\n",
       "isbn               ...                                               \n",
       "0002005018         ...                                         0.0   \n",
       "000648302X         ...                                         0.0   \n",
       "000649840X         ...                                         0.0   \n",
       "0020264763         ...                                         0.0   \n",
       "0020264801         ...                                         0.0   \n",
       "\n",
       "            Savich, Dillon (Fictitious character)  Science fiction  Self-Help  \\\n",
       "isbn                                                                            \n",
       "0002005018                                    0.0              0.0        0.0   \n",
       "000648302X                                    0.0              0.0        0.0   \n",
       "000649840X                                    0.0              0.0        0.0   \n",
       "0020264763                                    0.0              0.0        0.0   \n",
       "0020264801                                    0.0              0.0        0.0   \n",
       "\n",
       "            Social Science  Star Trek fiction  Travel  Travelers' writings  \\\n",
       "isbn                                                                         \n",
       "0002005018             0.0                0.0     0.0                  0.0   \n",
       "000648302X             0.0                0.0     0.0                  0.0   \n",
       "000649840X             0.0                0.0     0.0                  0.0   \n",
       "0020264763             0.0                0.0     0.0                  0.0   \n",
       "0020264801             0.0                0.0     0.0                  0.0   \n",
       "\n",
       "            True Crime  Yorkshire (England)  \n",
       "isbn                                         \n",
       "0002005018         0.0                  0.0  \n",
       "000648302X         0.0                  0.0  \n",
       "000649840X         0.0                  0.0  \n",
       "0020264763         0.0                  0.0  \n",
       "0020264801         0.0                  0.0  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1466, 158)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_item.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `df_item`, there are **1,466** books and **158** genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the merged dataframe of `books`, `ratings`, `users` and get the record which matched the 1,466 books in `df_item`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged = merge_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>country</th>\n",
       "      <th>province</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>url_s</th>\n",
       "      <th>url_m</th>\n",
       "      <th>url_l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "      <td>tyler, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>usa</td>\n",
       "      <td>texas</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>cincinnati, ohio, usa</td>\n",
       "      <td>23.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>ohio</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6543</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "      <td>strafford, missouri, usa</td>\n",
       "      <td>34.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>missouri</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8680</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>st. charles county, missouri, usa</td>\n",
       "      <td>2.0</td>\n",
       "      <td>usa</td>\n",
       "      <td>missouri</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10314</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>9</td>\n",
       "      <td>beaverton, oregon, usa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>usa</td>\n",
       "      <td>oregon</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     user        isbn  rating                           location   age  \\\n",
       "0  276725  034545104X       0                  tyler, texas, usa   NaN   \n",
       "1    2313  034545104X       5              cincinnati, ohio, usa  23.0   \n",
       "2    6543  034545104X       0           strafford, missouri, usa  34.0   \n",
       "3    8680  034545104X       5  st. charles county, missouri, usa   2.0   \n",
       "4   10314  034545104X       9             beaverton, oregon, usa   NaN   \n",
       "\n",
       "  country   province                 title      author  pub_year  \\\n",
       "0     usa      texas  Flesh Tones: A Novel  M. J. Rose    2002.0   \n",
       "1     usa       ohio  Flesh Tones: A Novel  M. J. Rose    2002.0   \n",
       "2     usa   missouri  Flesh Tones: A Novel  M. J. Rose    2002.0   \n",
       "3     usa   missouri  Flesh Tones: A Novel  M. J. Rose    2002.0   \n",
       "4     usa     oregon  Flesh Tones: A Novel  M. J. Rose    2002.0   \n",
       "\n",
       "          publisher                                              url_s  \\\n",
       "0  Ballantine Books  http://images.amazon.com/images/P/034545104X.0...   \n",
       "1  Ballantine Books  http://images.amazon.com/images/P/034545104X.0...   \n",
       "2  Ballantine Books  http://images.amazon.com/images/P/034545104X.0...   \n",
       "3  Ballantine Books  http://images.amazon.com/images/P/034545104X.0...   \n",
       "4  Ballantine Books  http://images.amazon.com/images/P/034545104X.0...   \n",
       "\n",
       "                                               url_m  \\\n",
       "0  http://images.amazon.com/images/P/034545104X.0...   \n",
       "1  http://images.amazon.com/images/P/034545104X.0...   \n",
       "2  http://images.amazon.com/images/P/034545104X.0...   \n",
       "3  http://images.amazon.com/images/P/034545104X.0...   \n",
       "4  http://images.amazon.com/images/P/034545104X.0...   \n",
       "\n",
       "                                               url_l  \n",
       "0  http://images.amazon.com/images/P/034545104X.0...  \n",
       "1  http://images.amazon.com/images/P/034545104X.0...  \n",
       "2  http://images.amazon.com/images/P/034545104X.0...  \n",
       "3  http://images.amazon.com/images/P/034545104X.0...  \n",
       "4  http://images.amazon.com/images/P/034545104X.0...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11676     11144\n",
       "198711     6456\n",
       "153662     5814\n",
       "98391      5779\n",
       "35859      5646\n",
       "212898     4289\n",
       "278418     3996\n",
       "76352      3329\n",
       "110973     2971\n",
       "235105     2943\n",
       "Name: user, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top users number and their number of ratings given\n",
    "df_merged.user.value_counts().sort_values(ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_merged[df_merged['isbn'].isin(df_item.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create isbn and category dict\n",
    "isbn_cat_dict = pd.Series(books_wd['categories'].values,index=books_wd['isbn']).to_dict()\n",
    "\n",
    "#create isbn and description dict\n",
    "isbn_des_dict = pd.Series(books_wd['description'].values,index=books_wd['isbn']).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kevin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/Kevin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_final['category'] = df_final['isbn'].map(isbn_cat_dict)\n",
    "df_final['description'] = df_final['isbn'].map(isbn_des_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72821, 16)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final[['user','rating','isbn','title','author','publisher','pub_year','category','description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>276746</td>\n",
       "      <td>0</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>Manhattan Hunt Club</td>\n",
       "      <td>JOHN SAUL</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>When college student Jeff Converse is wrongly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>278026</td>\n",
       "      <td>8</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>Manhattan Hunt Club</td>\n",
       "      <td>JOHN SAUL</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>When college student Jeff Converse is wrongly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>243</td>\n",
       "      <td>6</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>Manhattan Hunt Club</td>\n",
       "      <td>JOHN SAUL</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>When college student Jeff Converse is wrongly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>645</td>\n",
       "      <td>0</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>Manhattan Hunt Club</td>\n",
       "      <td>JOHN SAUL</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>When college student Jeff Converse is wrongly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>Manhattan Hunt Club</td>\n",
       "      <td>JOHN SAUL</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>When college student Jeff Converse is wrongly ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  rating        isbn                title     author  \\\n",
       "501  276746       0  0449006522  Manhattan Hunt Club  JOHN SAUL   \n",
       "502  278026       8  0449006522  Manhattan Hunt Club  JOHN SAUL   \n",
       "503     243       6  0449006522  Manhattan Hunt Club  JOHN SAUL   \n",
       "504     645       0  0449006522  Manhattan Hunt Club  JOHN SAUL   \n",
       "505    2010       0  0449006522  Manhattan Hunt Club  JOHN SAUL   \n",
       "\n",
       "            publisher  pub_year category  \\\n",
       "501  Ballantine Books    2002.0  Fiction   \n",
       "502  Ballantine Books    2002.0  Fiction   \n",
       "503  Ballantine Books    2002.0  Fiction   \n",
       "504  Ballantine Books    2002.0  Fiction   \n",
       "505  Ballantine Books    2002.0  Fiction   \n",
       "\n",
       "                                           description  \n",
       "501  When college student Jeff Converse is wrongly ...  \n",
       "502  When college student Jeff Converse is wrongly ...  \n",
       "503  When college student Jeff Converse is wrongly ...  \n",
       "504  When college student Jeff Converse is wrongly ...  \n",
       "505  When college student Jeff Converse is wrongly ...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **72,821** ratings of the **1,466** books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = pd.pivot_table(df_final, values='rating', index=['isbn'], columns = ['user'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>user</th>\n",
       "      <th>10</th>\n",
       "      <th>100004</th>\n",
       "      <th>100009</th>\n",
       "      <th>10001</th>\n",
       "      <th>100029</th>\n",
       "      <th>100035</th>\n",
       "      <th>10005</th>\n",
       "      <th>100053</th>\n",
       "      <th>100066</th>\n",
       "      <th>100067</th>\n",
       "      <th>...</th>\n",
       "      <th>99885</th>\n",
       "      <th>99894</th>\n",
       "      <th>999</th>\n",
       "      <th>9991</th>\n",
       "      <th>99946</th>\n",
       "      <th>99955</th>\n",
       "      <th>99963</th>\n",
       "      <th>99973</th>\n",
       "      <th>99996</th>\n",
       "      <th>99997</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0002005018</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000648302X</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000649840X</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020264763</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020264801</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22950 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "user        10  100004  100009  10001  100029  100035  10005  100053  100066  \\\n",
       "isbn                                                                           \n",
       "0002005018 NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN     NaN   \n",
       "000648302X NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN     NaN   \n",
       "000649840X NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN     NaN   \n",
       "0020264763 NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN     NaN   \n",
       "0020264801 NaN     NaN     NaN    NaN     NaN     NaN    NaN     NaN     NaN   \n",
       "\n",
       "user        100067  ...    99885  99894  999  9991  99946  99955  99963  \\\n",
       "isbn                ...                                                   \n",
       "0002005018     NaN  ...      NaN    NaN  NaN   NaN    NaN    NaN    NaN   \n",
       "000648302X     NaN  ...      NaN    NaN  NaN   NaN    NaN    NaN    NaN   \n",
       "000649840X     NaN  ...      NaN    NaN  NaN   NaN    NaN    NaN    NaN   \n",
       "0020264763     NaN  ...      NaN    NaN  NaN   NaN    NaN    NaN    NaN   \n",
       "0020264801     NaN  ...      NaN    NaN  NaN   NaN    NaN    NaN    NaN   \n",
       "\n",
       "user        99973  99996  99997  \n",
       "isbn                             \n",
       "0002005018    NaN    NaN    NaN  \n",
       "000648302X    NaN    NaN    NaN  \n",
       "000649840X    NaN    NaN    NaN  \n",
       "0020264763    NaN    NaN    NaN  \n",
       "0020264801    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 22950 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the user number\n",
    "users_no = rating.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty dataframe\n",
    "df_users = pd.DataFrame(columns = df_item.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accidents</th>\n",
       "      <th>Action and adventure</th>\n",
       "      <th>Actors</th>\n",
       "      <th>Actresses</th>\n",
       "      <th>Adoptees</th>\n",
       "      <th>Adventure stories</th>\n",
       "      <th>Affirmations</th>\n",
       "      <th>African American fiction</th>\n",
       "      <th>African American men</th>\n",
       "      <th>African American psychologists</th>\n",
       "      <th>...</th>\n",
       "      <th>Ryan, Jack (Fictitious character)</th>\n",
       "      <th>Savich, Dillon (Fictitious character)</th>\n",
       "      <th>Science fiction</th>\n",
       "      <th>Self-Help</th>\n",
       "      <th>Social Science</th>\n",
       "      <th>Star Trek fiction</th>\n",
       "      <th>Travel</th>\n",
       "      <th>Travelers' writings</th>\n",
       "      <th>True Crime</th>\n",
       "      <th>Yorkshire (England)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Accidents, Action and adventure, Actors, Actresses, Adoptees, Adventure stories, Affirmations, African American fiction, African American men, African American psychologists, Age groups, Ahab, Captain (Fictitious character), Alchemists, Alcoholism, Altruism, Alzheimer's disease, American fiction, American literature, Americans, Andalusia (Spain), Animals, Anti-Catholicism, Antiques, Apocalyptic literature, Arabic fiction, Art, Artists, Astrology, Authors, American, Authors, Chilean, Baggins, Frodo (Fictitious character), Banks, Alan (Fictitious character), Bible, Biographical fiction, Biography &amp; Autobiography, Body, Mind &amp; Spirit, Book clubs (Discussion groups), Books and reading, Boston (Mass.), Boulder (Colo.), Boxcar children (Fictitious characters), Boys, Brain, Brooklyn (New York, N.Y.), Brunetti, Guido (Fictitious character), Business &amp; Economics, Business intelligence, Businessmen, Businesswomen, Calhoun, Mackenzie (Fictitious character), California, Canon (Literarature), Catskill Mountains Region (N.Y.), Childlessness, Children's stories, Comics &amp; Graphic Novels, Computers, Conduct of life, Confession, Continental European fiction (Fictional works by one author)., Cooking, Courtship, Covenant, Thomas (Fictitious character), Crafts &amp; Hobbies, Creative activities and seat work, Curiosities and wonders, Design, Detective and mystery stories, Diary fiction, Donation of organs, tissues, etc, Dracula, Count (Fictitious character), Dragons, Drama, Drug abuse, Drug traffic, Duitse fiksie, Education, Egypt, End of the world, England, English fiction, FICTION, Fairies, Fairy tales, Families, Family &amp; Relationships, Famines, Fantasy, Fantasy fiction, Female offenders, Feminists, Fiction, Fiction in English, Florida, Foreign Language Study, Fortune-telling by colors, France, Frankenstein (Fictitious character), Geishas, Generation X, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 158 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22950/22950 [08:05<00:00, 47.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(users_no))):\n",
    "    working_df = df_item.mul(rating.iloc[:,i], axis=0)\n",
    "    working_df.replace(0, np.NaN, inplace=True)    \n",
    "    df_users.loc[users_no[i]] = working_df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accidents</th>\n",
       "      <th>Action and adventure</th>\n",
       "      <th>Actors</th>\n",
       "      <th>Actresses</th>\n",
       "      <th>Adoptees</th>\n",
       "      <th>Adventure stories</th>\n",
       "      <th>Affirmations</th>\n",
       "      <th>African American fiction</th>\n",
       "      <th>African American men</th>\n",
       "      <th>African American psychologists</th>\n",
       "      <th>...</th>\n",
       "      <th>Ryan, Jack (Fictitious character)</th>\n",
       "      <th>Savich, Dillon (Fictitious character)</th>\n",
       "      <th>Science fiction</th>\n",
       "      <th>Self-Help</th>\n",
       "      <th>Social Science</th>\n",
       "      <th>Star Trek fiction</th>\n",
       "      <th>Travel</th>\n",
       "      <th>Travelers' writings</th>\n",
       "      <th>True Crime</th>\n",
       "      <th>Yorkshire (England)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100009</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100029</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 158 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accidents  Action and adventure  Actors  Actresses  Adoptees  \\\n",
       "10            NaN                   NaN     NaN        NaN       NaN   \n",
       "100004        NaN                   NaN     NaN        NaN       NaN   \n",
       "100009        NaN                   NaN     NaN        NaN       NaN   \n",
       "10001         NaN                   NaN     NaN        NaN       NaN   \n",
       "100029        NaN                   NaN     NaN        NaN       NaN   \n",
       "\n",
       "        Adventure stories  Affirmations  African American fiction  \\\n",
       "10                    NaN           NaN                       NaN   \n",
       "100004                NaN           NaN                       NaN   \n",
       "100009                NaN           NaN                       NaN   \n",
       "10001                 NaN           NaN                       NaN   \n",
       "100029                NaN           NaN                       NaN   \n",
       "\n",
       "        African American men  African American psychologists  \\\n",
       "10                       NaN                             NaN   \n",
       "100004                   NaN                             NaN   \n",
       "100009                   NaN                             NaN   \n",
       "10001                    NaN                             NaN   \n",
       "100029                   NaN                             NaN   \n",
       "\n",
       "               ...           Ryan, Jack (Fictitious character)  \\\n",
       "10             ...                                         NaN   \n",
       "100004         ...                                         NaN   \n",
       "100009         ...                                         NaN   \n",
       "10001          ...                                         NaN   \n",
       "100029         ...                                         NaN   \n",
       "\n",
       "        Savich, Dillon (Fictitious character)  Science fiction  Self-Help  \\\n",
       "10                                        NaN              NaN        NaN   \n",
       "100004                                    NaN              NaN        NaN   \n",
       "100009                                    NaN              NaN        NaN   \n",
       "10001                                     NaN              NaN        NaN   \n",
       "100029                                    NaN              NaN        NaN   \n",
       "\n",
       "        Social Science  Star Trek fiction  Travel  Travelers' writings  \\\n",
       "10                 NaN                NaN     NaN                  NaN   \n",
       "100004             NaN                NaN     NaN                  NaN   \n",
       "100009             NaN                NaN     NaN                  NaN   \n",
       "10001              NaN                NaN     NaN                  NaN   \n",
       "100029             NaN                NaN     NaN                  NaN   \n",
       "\n",
       "        True Crime  Yorkshire (England)  \n",
       "10             NaN                  NaN  \n",
       "100004         NaN                  NaN  \n",
       "100009         NaN                  NaN  \n",
       "10001          NaN                  NaN  \n",
       "100029         NaN                  NaN  \n",
       "\n",
       "[5 rows x 158 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#user profile\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDF\n",
    "Let’s consider how common different terms are among our documents.  \n",
    "The dot product of article vectors and IDF vectors gives us the **weighted scores** of each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_frequency = df_item.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idf = (len(books_wd)/document_frequency).apply(np.log) #log inverse of DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The dot product of article vectors and IDF vectors gives us the weighted scores of each article.\n",
    "idf_df_item = df_item.mul(idf.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an empty dataframe\n",
    "df_predict = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22950/22950 [04:18<00:00, 88.80it/s] \n"
     ]
    }
   ],
   "source": [
    "#user predict by tfidf\n",
    "for i in tqdm(range(len(users_no))):\n",
    "    working_df = idf_df_item.mul(df_users.iloc[i], axis=1)\n",
    "    df_predict[users_no[i]] = working_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>100004</th>\n",
       "      <th>100009</th>\n",
       "      <th>10001</th>\n",
       "      <th>100029</th>\n",
       "      <th>100035</th>\n",
       "      <th>10005</th>\n",
       "      <th>100053</th>\n",
       "      <th>100066</th>\n",
       "      <th>100067</th>\n",
       "      <th>...</th>\n",
       "      <th>99885</th>\n",
       "      <th>99894</th>\n",
       "      <th>999</th>\n",
       "      <th>9991</th>\n",
       "      <th>99946</th>\n",
       "      <th>99955</th>\n",
       "      <th>99963</th>\n",
       "      <th>99973</th>\n",
       "      <th>99996</th>\n",
       "      <th>99997</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isbn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0002005018</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000648302X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000649840X</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020264763</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020264801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.777364</td>\n",
       "      <td>3.471705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.777364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.124534</td>\n",
       "      <td>2.198746</td>\n",
       "      <td>2.430193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.430193</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.909438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.083023</td>\n",
       "      <td>3.008811</td>\n",
       "      <td>2.893087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22950 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             10  100004    100009     10001  100029    100035  10005  \\\n",
       "isbn                                                                   \n",
       "0002005018  0.0     0.0  0.000000  0.000000     0.0  0.000000    0.0   \n",
       "000648302X  0.0     0.0  0.000000  0.000000     0.0  0.000000    0.0   \n",
       "000649840X  0.0     0.0  0.000000  0.000000     0.0  0.000000    0.0   \n",
       "0020264763  0.0     0.0  0.000000  0.000000     0.0  0.000000    0.0   \n",
       "0020264801  0.0     0.0  2.777364  3.471705     0.0  2.777364    0.0   \n",
       "\n",
       "              100053    100066    100067    ...     99885  99894       999  \\\n",
       "isbn                                        ...                              \n",
       "0002005018  0.000000  0.000000  0.000000    ...       0.0    0.0  0.000000   \n",
       "000648302X  0.000000  0.000000  0.000000    ...       0.0    0.0  0.000000   \n",
       "000649840X  0.000000  0.000000  0.000000    ...       0.0    0.0  0.000000   \n",
       "0020264763  0.000000  0.000000  0.000000    ...       0.0    0.0  0.000000   \n",
       "0020264801  3.124534  2.198746  2.430193    ...       0.0    0.0  2.430193   \n",
       "\n",
       "            9991     99946  99955  99963     99973     99996     99997  \n",
       "isbn                                                                    \n",
       "0002005018   0.0  0.000000    0.0    0.0  0.000000  0.000000  0.000000  \n",
       "000648302X   0.0  0.000000    0.0    0.0  0.000000  0.000000  0.000000  \n",
       "000649840X   0.0  0.000000    0.0    0.0  0.000000  0.000000  0.000000  \n",
       "0020264763   0.0  0.000000    0.0    0.0  0.000000  0.000000  0.000000  \n",
       "0020264801   0.0  1.909438    0.0    0.0  2.083023  3.008811  2.893087  \n",
       "\n",
       "[5 rows x 22950 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all user score predict of all books\n",
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def recommender(user_no):\n",
    "    \n",
    "    #get all book isbn\n",
    "    isbn_no = df_predict.index\n",
    "\n",
    "    #user predicted rating to all books\n",
    "    user_predicted_rating = df_predict['33570']\n",
    "\n",
    "    #combine book rating and book detail\n",
    "    user_rating_book = pd.concat([user_predicted_rating,books_wd.set_index('isbn')], axis=1)\n",
    "\n",
    "    #books already read by user\n",
    "    already_read = df_final[df_final['user'].isin(['33570'])]['isbn']\n",
    "\n",
    "    #recommendation without books being read by user\n",
    "    all_rec = user_rating_book[~user_rating_book.index.isin(already_read)]\n",
    "\n",
    "    return all_rec.sort_values(by=[user_no], ascending=False).iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kevin/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>33570</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>publisher</th>\n",
       "      <th>categories</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0449005569</th>\n",
       "      <td>2.430193</td>\n",
       "      <td>Love: A User's Guide</td>\n",
       "      <td>CLARE NAYLOR</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>When she catches the eye of London's handsomes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0449005410</th>\n",
       "      <td>2.430193</td>\n",
       "      <td>Horse Heaven (Ballantine Reader's Circle)</td>\n",
       "      <td>Jane Smiley</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>A novel set in the world of thoroughbred racin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0449130703</th>\n",
       "      <td>2.430193</td>\n",
       "      <td>The Number of the Beast</td>\n",
       "      <td>Robert Heinlein</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>Fawcett Books</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>The unusual adventures of four geniuses who ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0449130509</th>\n",
       "      <td>2.430193</td>\n",
       "      <td>Winterbourne</td>\n",
       "      <td>Susan Carroll</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>Fawcett</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Beloved author Susan Carroll took the romance ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0449006689</th>\n",
       "      <td>2.430193</td>\n",
       "      <td>Murder in Havana (Truman, Margaret, Capital Cr...</td>\n",
       "      <td>Margaret Truman</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fawcett Books</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Asked to investigate an American pharmaceutica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0449006344</th>\n",
       "      <td>2.430193</td>\n",
       "      <td>Angel Falls</td>\n",
       "      <td>KRISTIN HANNAH</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Liam will do anything to break his wife out of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>080411787X</th>\n",
       "      <td>2.430193</td>\n",
       "      <td>Acts of Love</td>\n",
       "      <td>JUDITH MICHAEL</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Ivy Books</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>A collection of letters written by a young act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0804117934</th>\n",
       "      <td>2.430193</td>\n",
       "      <td>The Silent Cry (William Monk Novels (Paperback))</td>\n",
       "      <td>Anne Perry</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Ivy Books</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>Victorian-era criminal investigator William Mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0449004503</th>\n",
       "      <td>2.430193</td>\n",
       "      <td>Death Rounds</td>\n",
       "      <td>PETER CLEMENT</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>Fawcett</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>The author, a former emergency room physician ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0441003257</th>\n",
       "      <td>2.430193</td>\n",
       "      <td>Good Omens</td>\n",
       "      <td>Neil Gaiman</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>Ace Books</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>When the armies of Heaven and Hell decide it's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               33570                                              title  \\\n",
       "0449005569  2.430193                               Love: A User's Guide   \n",
       "0449005410  2.430193          Horse Heaven (Ballantine Reader's Circle)   \n",
       "0449130703  2.430193                            The Number of the Beast   \n",
       "0449130509  2.430193                                       Winterbourne   \n",
       "0449006689  2.430193  Murder in Havana (Truman, Margaret, Capital Cr...   \n",
       "0449006344  2.430193                                        Angel Falls   \n",
       "080411787X  2.430193                                       Acts of Love   \n",
       "0804117934  2.430193   The Silent Cry (William Monk Novels (Paperback))   \n",
       "0449004503  2.430193                                       Death Rounds   \n",
       "0441003257  2.430193                                         Good Omens   \n",
       "\n",
       "                     author  pub_year         publisher categories  \\\n",
       "0449005569     CLARE NAYLOR    1999.0  Ballantine Books    Fiction   \n",
       "0449005410      Jane Smiley    2001.0  Ballantine Books    Fiction   \n",
       "0449130703  Robert Heinlein    1989.0     Fawcett Books    Fiction   \n",
       "0449130509    Susan Carroll    1987.0           Fawcett    Fiction   \n",
       "0449006689  Margaret Truman    2002.0     Fawcett Books    Fiction   \n",
       "0449006344   KRISTIN HANNAH    2001.0  Ballantine Books    Fiction   \n",
       "080411787X   JUDITH MICHAEL    1997.0         Ivy Books    Fiction   \n",
       "0804117934       Anne Perry    1998.0         Ivy Books    Fiction   \n",
       "0449004503    PETER CLEMENT    1999.0           Fawcett    Fiction   \n",
       "0441003257      Neil Gaiman    1996.0         Ace Books    Fiction   \n",
       "\n",
       "                                                  description  \n",
       "0449005569  When she catches the eye of London's handsomes...  \n",
       "0449005410  A novel set in the world of thoroughbred racin...  \n",
       "0449130703  The unusual adventures of four geniuses who ar...  \n",
       "0449130509  Beloved author Susan Carroll took the romance ...  \n",
       "0449006689  Asked to investigate an American pharmaceutica...  \n",
       "0449006344  Liam will do anything to break his wife out of...  \n",
       "080411787X  A collection of letters written by a young act...  \n",
       "0804117934  Victorian-era criminal investigator William Mo...  \n",
       "0449004503  The author, a former emergency room physician ...  \n",
       "0441003257  When the armies of Heaven and Hell decide it's...  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender('33570')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>publisher</th>\n",
       "      <th>pub_year</th>\n",
       "      <th>category</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>33570</td>\n",
       "      <td>8</td>\n",
       "      <td>0449006522</td>\n",
       "      <td>Manhattan Hunt Club</td>\n",
       "      <td>JOHN SAUL</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>When college student Jeff Converse is wrongly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188024</th>\n",
       "      <td>33570</td>\n",
       "      <td>6</td>\n",
       "      <td>0553583468</td>\n",
       "      <td>Whisper of Evil (Hooper, Kay. Evil Trilogy.)</td>\n",
       "      <td>Kay Hooper</td>\n",
       "      <td>Bantam Books</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>As a series of grisly murders terrorizes the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user  rating        isbn  \\\n",
       "520     33570       8  0449006522   \n",
       "188024  33570       6  0553583468   \n",
       "\n",
       "                                               title      author  \\\n",
       "520                              Manhattan Hunt Club   JOHN SAUL   \n",
       "188024  Whisper of Evil (Hooper, Kay. Evil Trilogy.)  Kay Hooper   \n",
       "\n",
       "               publisher  pub_year category  \\\n",
       "520     Ballantine Books    2002.0  Fiction   \n",
       "188024      Bantam Books    2002.0  Fiction   \n",
       "\n",
       "                                              description  \n",
       "520     When college student Jeff Converse is wrongly ...  \n",
       "188024  As a series of grisly murders terrorizes the s...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#books Read by user 33570\n",
    "df_final[df_final['user'].isin(['33570'])].sort_values(by=['rating'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pros\n",
    "* **User independence**: collaborative filtering needs other users' rating to find the similarity between the users and then give the suggestion. Instead, content-based method only have to analyze the items and user profile for recommendation.\n",
    "* **Transparency**: collaborative method gives you the recommendation because some unknown users have the same taste like you, but content-based method can tell you they recommend you the items based on what features. \n",
    "* **No cold start**: opposite to collaborative filtering, new items can be suggested before being rated by a substantial number of users.\n",
    "\n",
    "### Cons\n",
    "* **Limited content analysis**: if the content does not contain enough information to discriminate the items precisely, the recommendation will be not precisely at the end.\n",
    "* **Over-specialization**: content-based method provides a limit degree of novelty, since it has to match up the features of profile and items. A totally perfect content-based filtering may suggest nothing \"surprised.\" \n",
    "* **New user**: when there's not enough information to build a solid profile for a user, the recommendation could not be provided correctly. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference  \n",
    "https://www.analyticsvidhya.com/blog/2015/08/beginners-guide-learn-content-based-recommender-systems/  \n",
    "https://towardsdatascience.com/learning-to-make-recommendations-745d13883951  \n",
    "http://findoutyourfavorite.blogspot.com/2012/04/content-based-filtering.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
